# üìò Parte 3 ‚Äì Agentes e Tools no LangChain

## Vis√£o geral da parte

Esta parte do estudo tem como objetivo demonstrar **como LLMs podem ir al√©m de responder texto**, passando a **executar a√ß√µes controladas** por meio de ferramentas externas (*tools*). Aqui o LangChain √© apresentado como uma **camada de orquestra√ß√£o** entre o modelo de linguagem e fun√ß√µes do mundo real.

### Problemas que essa parte resolve

Antes de agentes e tools, o LLM:

* Apenas gera texto
* Pode ‚Äúalucinar‚Äù respostas
* N√£o tem como executar c√≥digo ou consultar fontes externas de forma confi√°vel

Com agentes e tools, passamos a:

* Delegar tarefas espec√≠ficas para fun√ß√µes determin√≠sticas
* Restringir a fonte de verdade √†s ferramentas
* Tornar o comportamento do modelo **mais previs√≠vel e audit√°vel**

### Conex√£o com as pr√≥ximas partes

Esta parte prepara o terreno para:

* **Chains mais complexas** (orquestra√ß√£o multi-etapas)
* **RAG (Retrieval-Augmented Generation)**
* **Agentes mais aut√¥nomos e especializados**
* **Aplica√ß√µes reais com seguran√ßa e controle**

---

## Arquivo 1 ‚Äì `1-agente-react-e-tools.py`

### O que este arquivo faz

Implementa um **agente ReAct (Reason + Act)** usando um *prompt manual*, onde o LLM:

1. Raciocina explicitamente (Thought)
2. Decide qual ferramenta usar (Action)
3. Executa a ferramenta
4. Observa o resultado
5. Repete o ciclo at√© chegar √† resposta final

### Conceito demonstrado

* **Padr√£o ReAct**
* Agentes baseados em **parsing de texto**
* Forte depend√™ncia de prompt

### Estrutura geral do c√≥digo

#### 1. Carregamento de ambiente

```python
load_dotenv()
```

Carrega vari√°veis de ambiente, normalmente usadas para chaves de API.

---

#### 2. Defini√ß√£o das tools

```python
@tool("calculator", return_direct=True)
def calculator(expression: str) -> str:
```

Pontos importantes:

* `@tool` transforma uma fun√ß√£o Python em uma tool do LangChain
* `return_direct=True` indica que o retorno da tool pode ser usado diretamente como resposta final
* Uso de `eval` **√© propositalmente perigoso**, servindo apenas para fins did√°ticos

A fun√ß√£o:

* Avalia uma express√£o matem√°tica
* Soma `+3` ao resultado (detalhe importante para mostrar que a tool √© a fonte da verdade)

---

```python
@tool("web_search_mock")
def web_search_mock(query: str) -> str:
```

Simula uma busca na web usando um dicion√°rio fixo. Isso permite:

* Testar agentes sem depender de APIs externas
* Demonstrar que o LLM **n√£o sabe as respostas**, apenas usa ferramentas

---

#### 3. Inicializa√ß√£o do modelo

```python
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.5)
```

Caracter√≠sticas:

* Modelo **chat-based**
* Temperatura moderada
* Totalmente substitu√≠vel por outros modelos compat√≠veis

---

#### 4. Prompt ReAct manual

```python
prompt = PromptTemplate.from_template("""
...
""")
```

Este √© o cora√ß√£o do padr√£o ReAct:

* Define explicitamente o formato de sa√≠da
* Obriga o modelo a seguir o ciclo Thought ‚Üí Action ‚Üí Observation
* Pro√≠be uso de conhecimento pr√©vio

‚ö†Ô∏è **Fragilidade**: qualquer erro de formata√ß√£o quebra o agente.

---

#### 5. Cria√ß√£o do agente

```python
agent_chain = create_react_agent(llm, tools, prompt)
```

Aqui o LangChain:

* Injeta as tools no prompt
* Controla o ciclo de execu√ß√£o

---

#### 6. Executor

```python
agent_executor = AgentExecutor.from_agent_and_tools(...)
```

Responsabilidades do `AgentExecutor`:

* Executar o loop do agente
* Controlar n√∫mero m√°ximo de itera√ß√µes
* Lidar com erros de parsing

---

### Quando usar este padr√£o

* Ensino e aprendizado
* Demonstra√ß√£o conceitual de agentes
* Depura√ß√£o de racioc√≠nio do modelo

### Limita√ß√µes

* Fr√°gil em produ√ß√£o
* Parsing de texto √© inst√°vel
* Alto acoplamento ao prompt

---

## Arquivo 1.1 ‚Äì `1.1-agente-tool-calling.py`

### O que este arquivo faz

Implementa um agente usando **Tool Calling**, onde:

* O modelo **n√£o precisa seguir um formato textual r√≠gido**
* O LangChain intercepta chamadas estruturadas √†s tools

### Conceito demonstrado

* **Tool Calling nativo**
* Abordagem recomendada para aplica√ß√µes reais

---

### Principais diferen√ßas estruturais

#### Prompt baseado em chat

```python
prompt = ChatPromptTemplate.from_messages([
    ("system", "..."),
    ("human", "{input}"),
    ("placeholder", "{agent_scratchpad}")
])
```

Vantagens:

* Mais natural para modelos chat
* Menos dependente de formata√ß√£o manual

---

#### Cria√ß√£o do agente

```python
agent = create_tool_calling_agent(
    llm=llm,
    tools=tools,
    prompt=prompt
)
```

Aqui:

* O modelo retorna **estruturas internas**, n√£o texto livre
* O LangChain executa a tool automaticamente

---

### Vantagens do Tool Calling

* Maior robustez
* Melhor controle
* Ideal para produ√ß√£o
* Menos erros de parsing

### Quando usar

* Sistemas reais
* APIs
* Backends
* Aplica√ß√µes com requisitos de confiabilidade

---

## Arquivo 2 ‚Äì `2-agente-react-usando-prompt-hub.py`

### O que este arquivo faz

Reimplementa o agente ReAct, mas utilizando um **prompt padr√£o do LangChain Hub**.

```python
prompt = hub.pull("hwchase17/react")
```

---

### Conceito demonstrado

* **Reuso de prompts consolidados**
* Padroniza√ß√£o
* Menor esfor√ßo manual

---

### Vantagens do Prompt Hub

* Prompt testado pela comunidade
* Menos erros
* Melhor manuten√ß√£o

### Limita√ß√µes

* Continua sendo parsing de texto
* Ainda n√£o ideal para produ√ß√£o

---

## Compara√ß√£o entre os arquivos

| Abordagem    | Arquivo | Robustez | Uso recomendado    |
| ------------ | ------- | -------- | ------------------ |
| ReAct manual | 1       | Baixa    | Ensino             |
| Tool Calling | 1.1     | Alta     | Produ√ß√£o           |
| ReAct Hub    | 2       | M√©dia    | Ensino estruturado |

---

## Aspectos dependentes vs independentes de modelo

### Dependentes de modelo

* Chat models vs completion models
* Suporte a tool calling nativo
* Formato de mensagens

### Independentes (abstra√ß√µes LangChain)

* `@tool`
* `AgentExecutor`
* Orquestra√ß√£o

### Boas pr√°ticas

* Isolar l√≥gica de neg√≥cio nas tools
* Trocar modelos sem alterar ferramentas
* Evitar prompts excessivamente r√≠gidos

---

## Boas pr√°ticas e erros comuns

### Erros comuns

* Confiar no modelo em vez das tools
* Usar ReAct em produ√ß√£o
* N√£o limitar itera√ß√µes

### Padr√µes recomendados

* Tool Calling para sistemas reais
* ReAct apenas para aprendizado
* Tools pequenas e determin√≠sticas

---

## Resumo final

### Principais aprendizados

* LLMs podem agir, n√£o apenas responder
* Tools s√£o a fonte de verdade
* ReAct √© did√°tico, Tool Calling √© pr√°tico

### Checklist do aluno

* [x] Entender o papel do AgentExecutor
* [x] Criar tools com `@tool`
* [x] Diferenciar ReAct de Tool Calling
* [x] Saber quando usar cada abordagem

---

‚úÖ Ao concluir esta parte, voc√™ entende **como transformar racioc√≠nio em a√ß√£o**, com controle, seguran√ßa e clareza arquitetural.
